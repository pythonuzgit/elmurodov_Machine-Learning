#  Machine learning with Python <h1>
*Within the field of machine learning, there are two main types of tasks: supervised and unsupervised. Scikit-learn provides a wide selection of supervised and unsupervised learning algorithms.* 

****Scikit-Learn** is built on top several common data and math python libraries.**

* NumPy: a library for scientific computing, Linear Algebra and array package.

* Pandas: it provides DataFrame class. Data structures and analysis.

* Matplotlib: Data visualization, allows to create various 2d and 3d groups.

* SciPy: Fundamental library for scientific computing.

* SymPy: Symbolic mathematics.

****Supervised** Learning**

 Supervised learning algorithms can be used to solve both and classification and regression problems.

**Linear Regresion:** 
This Supervised Learning algorithm is used to predict continuous, numerical values based on given data input. Linear Regression tries to find parameters of the linear function, so the distance between the all the points and the like is as small as possible.
[Example](https://github.com/pythonuzgit/elmurodov_linearregression/blob/master/LinearRegression%20with%20cars%20datasets.ipynb)

**Logistic regression:** 
as a tool for building model which is used to a descrete set of classes. Logistic regression is commonly used when the response variable is continuous and a more complex cost function, this cost function can be defined as the 'Sigmoid function'.
[Example 1](https://github.com/pythonuzgit/samuz/blob/master/Logistic%20Regression%20.ipynb)
and [see also Example 2](https://github.com/pythonuzgit/elmurodov_logistic)

**k-nearest neigbors:** 
k-nearest neighbor algorithm (KNN) is a non-parmetric method and can be used for both classification and regression problem.
[Example](https://github.com/pythonuzgit/samuz/blob/master/k%20nearest%20neighbors%20classifications.ipynb)

**Support vector machines (SVM):** 
SVMs are a set of related supervised learning methods used for classification and regression. Support vector machines can be defined as systems which use hypothesis space of a linear functions in a high dimensional feature space, trained with a learning algorithm from optimization theory that implements a learning bias derived from statistical learning theory. 
[Example](https://github.com/pythonuzgit/samuz/blob/master/Support%20Vector%20Machine%20with%20Nonlinear%20kernel.ipynb)


**Random Forest**
[Example](https://github.com/pythonuzgit/elmurodov_RandomForest.git)


**Naive Bayes:** 
algorithm can be defined as a supervised classification algorithm which is based on Bayes' theorem.
[Example](https://github.com/pythonuzgit/samuz/blob/master/Naive%20Bayes%20Classifier%20with%20fuit_test.csv%20data.ipynb)

**Artificial Neural Network (ANNs):**
ANNs are the most commonly used tools in Machine Learning. A neural network is a statistical tool to interpret a set of features in the input data and it tries to either classify the input(Classification) and predict the output based on a continuous input(Regression).
The process of creating a neural network in Python begins with the most basic form, a single perceptron. We can extend the discussion to multilayer perceptrons, or more commonly known as artificial neural networks.
[Example 1](https://github.com/pythonuzgit/elmurodov) and
[Example 2](https://github.com/pythonuzgit/elmurodov/blob/master/Artificial%20Neural%20Networks%20with%20climate-model-simulation-crashes_csv.ipynb) and see also
[GitHub](https://github.com/pythonuzgit/elmurodov/blob/master/Neural_Network%20with%20diabets%20data.ipynb)





****Unsupervised** learning**

Unsupervised learning algorithm will be use a metric such as distance in order to identify how close a set of points are to each other and how far apart two such groups are.

**k-Means cluster:** 
K-Means clustering is one of the most commonly used clustering algorithms, which belong to the family of unsupervised machine learning models. It tries to find cluster centers that are representative of certain regions of the data. Therefore, the specific algorithm that you want to might depend on the problem you are trying to solve and also on what algorithm are available in the specific package that you are using. As we know some of the first clustering algorithm consisted of simply finding the centroid positions that minimize the distances to all the points in each cluster. The points in each cluster are closer to that centroid than other cluster centroids. As might be obvious at this point, the hardest part with this is figuring out how many clusters there are.
[Example](https://github.com/pythonuzgit/samuz/blob/master/K-Means%20Clusters%20with%20ipl.csv.ipynb)


**Principal Component analysis (PCA):**
PCA is an unsupervised learning method.
PCA is an important technique to undersand in the fields of statistics and data science/machine learning. PCA simplifies the complexity in high-dimensional data. It does this by transforming the data into fewer dimensions, which act as summaries of features. PCA is fundamentally a dimensionality reduction algorithm, but it can also be useful as a tool for visualization, for noise filtering, for feature extraction and engineering, and much more.
[Example](https://github.com/pythonuzgit/elmurodov_pca/blob/master/Principal%20Component%20analysis%20with%20motor%20datasets.ipynb)


**A Gaussian Mixture Models (GMM):**
GMM is a category of probabilistic model which states that all generated data points are derived from a mixture of a finite Gaussian distributions that has no known parameters.
Gaussian mixture models are very useful when it comes to modeling data, especially data which comes from several groups.
[Example](https://github.com/pythonuzgit/elmurodov_gmm/blob/master/Gaussian%20Mixture%20Model%20(GMM)%20with%20motor%20datasets.ipynb)



